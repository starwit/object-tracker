Total time: 54.1373 s
File: /home/edgar/Documents/Arbeit/Tracker_Project/object-tracker/objecttracker/tracker.py
Function: get at line 38

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    38                                               @GET_DURATION.time()
    39                                               @torch.no_grad()
    40                                               @profile
    41                                               def get(self, input_proto):        
    42       299    7516850.6  25140.0     13.9          input_image, detection_proto = self._unpack_proto(input_proto)
    43                                               
    44       299        695.2      2.3      0.0          inference_start = time.monotonic_ns()
    45       299      14241.3     47.6      0.0          det_array = self._prepare_detection_input(detection_proto)
    46                                           
    47       299   46363221.1 155060.9     85.6          tracking_output_array = self.tracker.update(det_array, input_image)
    48                                           
    49       299       3072.6     10.3      0.0          OBJECT_COUNTER.inc(len(tracking_output_array))
    50                                                   
    51       299        741.1      2.5      0.0          inference_time_us = (time.monotonic_ns() - inference_start) // 1000
    52                                           
    53       299         88.5      0.3      0.0          num_cars = len(det_array)
    54                                           
    55       299     238430.6    797.4      0.4          return self._create_output(tracking_output_array, detection_proto, inference_time_us, num_cars)

Total time: 7.64108 s
File: /home/edgar/Documents/Arbeit/Tracker_Project/object-tracker/objecttracker/tracker.py
Function: _unpack_proto at line 66

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    66                                               @profile
    67                                               def _unpack_proto(self, detection_proto_raw):
    68       299       1169.4      3.9      0.0          detection_proto = DetectionOutput()
    69       299      48001.1    160.5      0.6          detection_proto.ParseFromString(detection_proto_raw)
    70                                           
    71       299        678.4      2.3      0.0          input_frame = detection_proto.frame
    72       299    7591080.2  25388.2     99.3          input_image = get_raw_frame_data(input_frame)
    73                                           
    74       299        146.5      0.5      0.0          return input_image, detection_proto
    
Total time: 50.8759 s
File: /home/edgar/Documents/Arbeit/Tracker_Project/object-tracker/objecttracker/trackingimpl/deepocsort/ocsort.py
Function: update at line 359

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   359                                               @profile
   360                                               def update(self, dets, img_numpy, tag='blub'):
   361                                                   """
   362                                                   Params:
   363                                                     dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]
   364                                                   Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).
   365                                                   Returns the a similar array, where the last column is the object ID.
   366                                                   NOTE: The number of objects returned may differ from the number of detections provided.
   367                                                   """
   368       299       1216.4      4.1      0.0          scores = dets[:, 4]
   369                                                   
   370       299       6275.1     21.0      0.0          remain_inds = scores > self.det_thresh
   371       299       5730.1     19.2      0.0          dets = dets[remain_inds]
   372       299       1004.8      3.4      0.0          self.height, self.width = img_numpy.shape[:2]
   373                                           
   374                                                   # Rescale
   375                                                   #scale = min(img_tensor.shape[2] / img_numpy.shape[0], img_tensor.shape[3] / img_numpy.shape[1])
   376                                                   #dets[:, :4] /= scale
   377                                           
   378                                                   # Embedding
   379       299        296.9      1.0      0.0          if self.embedding_off or dets.shape[0] == 0:
   380                                                       dets_embs = np.ones((dets.shape[0], 1))
   381                                                   else:
   382                                                       # (Ndets x X) [512, 1024, 2048]
   383                                                       #dets_embs = self.embedder.compute_embedding(img_numpy, dets[:, :4], tag)
   384       299   46660909.6 156056.6     91.7              dets_embs = self._get_features(dets[:, :4], img_numpy)
   385                                           
   386                                                   # CMC
   387       299        683.6      2.3      0.0          if not self.cmc_off:
   388       299    1316027.4   4401.4      2.6              transform = self.cmc.compute_affine(img_numpy, dets[:, :4], tag)
   389      7604       2449.2      0.3      0.0              for trk in self.trackers:
   390      7305     615555.0     84.3      1.2                  trk.apply_affine_correction(transform)
   391                                           
   392       299       5079.9     17.0      0.0          trust = (dets[:, 4] - self.det_thresh) / (1 - self.det_thresh)
   393       299        175.6      0.6      0.0          af = self.alpha_fixed_emb
   394                                                   # From [self.alpha_fixed_emb, 1], goes to 1 as detector is less confident
   395       299       3000.0     10.0      0.0          dets_alpha = af + (1 - af) * (1 - trust)
   396                                           
   397                                                   # get predicted locations from existing trackers.
   398       299        703.1      2.4      0.0          trks = np.zeros((len(self.trackers), 5))
   399       299         65.4      0.2      0.0          trk_embs = []
   400       299         49.5      0.2      0.0          to_del = []
   401       299         56.8      0.2      0.0          ret = []
   402      7604       3807.8      0.5      0.0          for t, trk in enumerate(trks):
   403      7305     246544.5     33.8      0.5              pos = self.trackers[t].predict()[0]
   404      7305       9497.2      1.3      0.0              trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]
   405      7305      50036.9      6.8      0.1              if np.any(np.isnan(pos)):
   406                                                           to_del.append(t)
   407                                                       else:  
   408      7305      14518.5      2.0      0.0                  trk_embs.append(self.trackers[t].get_emb())
   409       299      50407.7    168.6      0.1          trks = np.ma.compress_rows(np.ma.masked_invalid(trks))
   410                                           
   411       299        174.6      0.6      0.0          if len(trk_embs) > 0:
   412       298      65648.9    220.3      0.1              trk_embs = np.vstack(trk_embs)
   413                                                   else:
   414         1          1.9      1.9      0.0              trk_embs = np.array(trk_embs)
   415                                           
   416       299        537.7      1.8      0.0          for t in reversed(to_del):
   417                                                       self.trackers.pop(t)
   418                                           
   419       299       7266.7     24.3      0.0          velocities = np.array([trk.velocity if trk.velocity is not None else np.array((0, 0)) for trk in self.trackers])
   420       299       4024.4     13.5      0.0          last_boxes = np.array([trk.last_observation for trk in self.trackers])
   421       299      16499.9     55.2      0.0          k_observations = np.array([k_previous_obs(trk.observations, trk.age, self.delta_t) for trk in self.trackers])
   422                                           
   423       299         51.0      0.2      0.0          """
   424                                                       First round of association
   425                                                   """
   426                                                   # (M detections X N tracks, final score)
   427       299        375.5      1.3      0.0          if self.embedding_off or dets.shape[0] == 0 or trk_embs.shape[0] == 0:
   428         1          0.1      0.1      0.0              stage1_emb_cost = None
   429                                                   else:
   430       298      38039.9    127.7      0.1              stage1_emb_cost = dets_embs @ trk_embs.T
   431       598     282219.5    471.9      0.6          matched, unmatched_dets, unmatched_trks = associate(
   432       299         41.5      0.1      0.0              dets,
   433       299         30.7      0.1      0.0              trks,
   434       299        158.4      0.5      0.0              self.iou_threshold,
   435       299         29.9      0.1      0.0              velocities,
   436       299         28.9      0.1      0.0              k_observations,
   437       299         58.9      0.2      0.0              self.inertia,
   438       299         29.3      0.1      0.0              stage1_emb_cost,
   439       299         83.5      0.3      0.0              self.w_association_emb,
   440       299         84.9      0.3      0.0              self.aw_off,
   441       299        167.8      0.6      0.0              self.aw_param,
   442                                                   )
   443      3933       2128.8      0.5      0.0          for m in matched:
   444      3634     915126.9    251.8      1.8              self.trackers[m[1]].update(dets[m[0], :5], dets[m[0], 5])
   445      3634     181714.7     50.0      0.4              self.trackers[m[1]].update_emb(dets_embs[m[0]], alpha=dets_alpha[m[0]])
   446                                           
   447       299         40.7      0.1      0.0          """
   448                                                       Second round of associaton by OCR
   449                                                   """
   450       299        230.6      0.8      0.0          if unmatched_dets.shape[0] > 0 and unmatched_trks.shape[0] > 0:
   451       135        941.3      7.0      0.0              left_dets = dets[unmatched_dets]
   452       135       6159.5     45.6      0.0              left_dets_embs = dets_embs[unmatched_dets]
   453       135        463.8      3.4      0.0              left_trks = last_boxes[unmatched_trks]
   454       135        751.8      5.6      0.0              left_trks_embs = trk_embs[unmatched_trks]
   455                                           
   456       135       7600.6     56.3      0.0              iou_left = self.asso_func(left_dets, left_trks)
   457                                                       # TODO: is better without this
   458       135       8127.6     60.2      0.0              emb_cost_left = left_dets_embs @ left_trks_embs.T
   459       135         52.2      0.4      0.0              if self.embedding_off:
   460                                                           emb_cost_left = np.zeros_like(emb_cost_left)
   461       135        231.9      1.7      0.0              iou_left = np.array(iou_left)
   462       135        931.7      6.9      0.0              if iou_left.max() > self.iou_threshold:
   463        92         12.5      0.1      0.0                  """
   464                                                           NOTE: by using a lower threshold, e.g., self.iou_threshold - 0.1, you may
   465                                                           get a higher performance especially on MOT17/MOT20 datasets. But we keep it
   466                                                           uniform here for simplicity
   467                                                           """
   468        92      25088.8    272.7      0.0                  rematched_indices = linear_assignment(-iou_left)
   469        92         14.6      0.2      0.0                  to_remove_det_indices = []
   470        92         11.0      0.1      0.0                  to_remove_trk_indices = []
   471       249        232.7      0.9      0.0                  for m in rematched_indices:
   472       157        153.2      1.0      0.0                      det_ind, trk_ind = unmatched_dets[m[0]], unmatched_trks[m[1]]
   473       157        172.5      1.1      0.0                      if iou_left[m[0], m[1]] < self.iou_threshold:
   474        27          4.3      0.2      0.0                          continue
   475       130      62363.2    479.7      0.1                      self.trackers[trk_ind].update(dets[det_ind, :5], dets[det_ind, 5])
   476       130       8376.7     64.4      0.0                      self.trackers[trk_ind].update_emb(dets_embs[det_ind], alpha=dets_alpha[det_ind])
   477       130         48.5      0.4      0.0                      to_remove_det_indices.append(det_ind)
   478       130         42.3      0.3      0.0                      to_remove_trk_indices.append(trk_ind)
   479        92      12264.0    133.3      0.0                  unmatched_dets = np.setdiff1d(unmatched_dets, np.array(to_remove_det_indices))
   480        92       6829.2     74.2      0.0                  unmatched_trks = np.setdiff1d(unmatched_trks, np.array(to_remove_trk_indices))
   481                                           
   482      3840       1428.6      0.4      0.0          for m in unmatched_trks:
   483      3541     157459.7     44.5      0.3              self.trackers[m].update(None, None)
   484                                           
   485                                                   # create and initialise new trackers for unmatched detections
   486       386        334.0      0.9      0.0          for i in unmatched_dets:
   487       174      10294.4     59.2      0.0              trk = KalmanBoxTracker(
   488        87        558.9      6.4      0.0                  dets[i, :5], dets[i, 5], delta_t=self.delta_t, emb=dets_embs[i], alpha=dets_alpha[i], new_kf=not self.new_kf_off
   489                                                       )
   490        87         43.6      0.5      0.0              self.trackers.append(trk)
   491       299        176.7      0.6      0.0          i = len(self.trackers)
   492      7691       4185.4      0.5      0.0          for trk in reversed(self.trackers):
   493      7392      17091.0      2.3      0.0              if trk.last_observation.sum() < 0:
   494       767       4637.2      6.0      0.0                  d = trk.get_state()[0]
   495                                                       else:
   496      6625        777.0      0.1      0.0                  """
   497                                                           this is optional to use the recent observation or the kalman filter prediction,
   498                                                           we didn't notice significant difference here
   499                                                           """
   500      6625       3450.5      0.5      0.0                  d = trk.last_observation[:4]
   501      7392       2646.0      0.4      0.0              if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):
   502                                                           # +1 as MOT benchmark requires positive
   503      3851      17279.2      4.5      0.0                  ret.append(np.concatenate((d, [trk.id + 1], [trk.cls], [trk.conf])).reshape(1, -1))
   504      7392       1574.3      0.2      0.0              i -= 1
   505                                                       # remove dead tracklet
   506      7392       2253.5      0.3      0.0              if trk.time_since_update > self.max_age:
   507        67         84.1      1.3      0.0                  self.trackers.pop(i)
   508       299        133.4      0.4      0.0          if len(ret) > 0:
   509       299       1683.0      5.6      0.0              return np.concatenate(ret)
   510                                                   return np.empty((0, 5))


Total time: 42.0031 s
File: /home/edgar/Documents/Arbeit/Tracker_Project/object-tracker/objecttracker/trackingimpl/deepocsort/reid_multibackend.py
Function: forward at line 182

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   182                                               @profile
   183                                               def forward(self, im_batch):
   184                                                   
   185                                                   # preprocess batch
   186       299   22824660.9  76336.7     54.3          im_batch = self._preprocess(im_batch)
   187                                           
   188                                                   # batch to half
   189       299        255.4      0.9      0.0          if self.fp16 and im_batch.dtype != torch.float16:
   190                                                      im_batch = im_batch.half()
   191                                           
   192                                                   # batch processing
   193       299         73.7      0.2      0.0          features = []
   194       299        409.8      1.4      0.0          if self.pt:
   195       299   19175853.2  64133.3     45.7              features = self.model(im_batch)
   196                                                   elif self.jit:  # TorchScript
   197                                                       features = self.model(im_batch)
   198                                                   elif self.onnx:  # ONNX Runtime
   199                                                       im_batch = im_batch.cpu().numpy()  # torch to numpy
   200                                                       features = self.session.run([self.session.get_outputs()[0].name], {self.session.get_inputs()[0].name: im_batch})[0]
   201                                                   elif self.engine:  # TensorRT
   202                                                       if True and im_batch.shape != self.bindings['images'].shape:
   203                                                           i_in, i_out = (self.model_.get_binding_index(x) for x in ('images', 'output'))
   204                                                           self.context.set_binding_shape(i_in, im_batch.shape)  # reshape if dynamic
   205                                                           self.bindings['images'] = self.bindings['images']._replace(shape=im_batch.shape)
   206                                                           self.bindings['output'].data.resize_(tuple(self.context.get_binding_shape(i_out)))
   207                                                       s = self.bindings['images'].shape
   208                                                       assert im_batch.shape == s, f"input size {im_batch.shape} {'>' if self.dynamic else 'not equal to'} max model size {s}"
   209                                                       self.binding_addrs['images'] = int(im_batch.data_ptr())
   210                                                       self.context.execute_v2(list(self.binding_addrs.values()))
   211                                                       features = self.bindings['output'].data
   212                                                   elif self.xml:  # OpenVINO
   213                                                       im_batch = im_batch.cpu().numpy()  # FP32
   214                                                       features = self.executable_network([im_batch])[self.output_layer]
   215                                                   else:
   216                                                       print('Framework not supported at the moment, we are working on it...')
   217                                                       exit()
   218                                           
   219       299        823.2      2.8      0.0          if isinstance(features, (list, tuple)):
   220                                                       return self.from_numpy(features[0]) if len(features) == 1 else [self.from_numpy(x) for x in features]
   221                                                   else:
   222       299       1019.7      3.4      0.0              return self.from_numpy(features)

Total time: 23.7062 s
File: /home/edgar/Documents/Arbeit/Tracker_Project/object-tracker/objecttracker/trackingimpl/deepocsort/reid_multibackend.py
Function: _preprocess at line 169

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   169                                               @profile
   170                                               def _preprocess(self, im_batch):
   171                                           
   172       299         80.1      0.3      0.0          images = []
   173      4150       1786.1      0.4      0.0          for element in im_batch:
   174      3851    1572358.2    408.3      6.6              image = self.to_pil(element)
   175      3851   21904897.7   5688.1     92.4              image = self.preprocess(image)      # self.preprocess = T.Compose(self.transforms)
   176      3851       2659.3      0.7      0.0              images.append(image)
   177                                           
   178       299     223002.5    745.8      0.9          images = torch.stack(images, dim=0)
   179       299       1336.8      4.5      0.0          images = images.to(self.device)
   180                                           
   181       299         62.9      0.2      0.0          return images
